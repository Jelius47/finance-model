{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd8b1e-28b3-4f2c-8a2a-9ab81b785311",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from ta import add_all_ta_features\n",
    "from torch.nn.utils import weight_norm\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ================== 1. Enhanced Data Pipeline ==================\n",
    "def create_sequences(data, targets, window_size, horizon):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - window_size - horizon + 1):  # Fixed off-by-one error\n",
    "        X.append(data[i:i+window_size])\n",
    "        Y.append(targets[i+window_size:i+window_size+horizon])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Load data with proper error handling\n",
    "try:\n",
    "    df = pd.read_csv(\"AAPL_stock_data_2020_01_01.csv\")\n",
    "    # Verify the data has expected columns\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"CSV is missing required columns. Found: {df.columns.tolist()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Clean and prepare the data\n",
    "# Assuming first column contains dates\n",
    "date_col = df.columns[0]\n",
    "df = df.rename(columns={date_col: 'Date'})\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')  # Handle date parsing errors gracefully\n",
    "df = df.dropna(subset=['Date'])  # Remove rows with invalid dates\n",
    "df = df.set_index('Date')\n",
    "\n",
    "# Ensure numeric data types for critical columns\n",
    "for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Fill any remaining NaN values using forward fill then backward fill\n",
    "df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Add comprehensive technical features with error handling\n",
    "try:\n",
    "    df = add_all_ta_features(\n",
    "        df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error adding technical indicators: {e}\")\n",
    "    # Fallback to basic features if technical indicators fail\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['RSI'] = compute_rsi(df['Close'], 14)  # We'll define this function below\n",
    "\n",
    "# Define RSI calculation as fallback\n",
    "def compute_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(window=window).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(window=window).mean()\n",
    "    \n",
    "    # Handle zero division case\n",
    "    rs = gain / loss.replace(0, np.finfo(float).eps)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# Feature selection (choosing robust features)\n",
    "features = [\n",
    "    'Close', 'High', 'Low', 'Open', 'Volume'\n",
    "]\n",
    "\n",
    "# Add technical indicators if they exist\n",
    "ta_features = [\n",
    "    'momentum_rsi', 'volatility_bbh', 'trend_macd',\n",
    "    'volume_obv', 'volatility_atr', 'trend_ema_fast', 'trend_ema_slow'\n",
    "]\n",
    "\n",
    "# Only include features that exist in the dataframe\n",
    "features = [f for f in features if f in df.columns]\n",
    "ta_features = [f for f in ta_features if f in df.columns]\n",
    "features.extend(ta_features)\n",
    "\n",
    "# Check if we have enough features\n",
    "if len(features) < 5:\n",
    "    raise ValueError(f\"Not enough features available. Only found: {features}\")\n",
    "\n",
    "# Verify data quality\n",
    "if df[features].isna().any().any():\n",
    "    # Final safety check for NaNs, fill with column means\n",
    "    df[features] = df[features].fillna(df[features].mean())\n",
    "\n",
    "target = 'Close'\n",
    "\n",
    "# ================== 2. Advanced Normalization ==================\n",
    "# Ensure we have enough data\n",
    "if len(df) < 30:\n",
    "    raise ValueError(f\"Insufficient data points: {len(df)} (minimum 30 required)\")\n",
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "val_size = int(0.15 * len(df))\n",
    "\n",
    "# Use robust scaler to handle outliers\n",
    "scaler = RobustScaler()\n",
    "target_scaler = RobustScaler()  # Separate scaler for target\n",
    "\n",
    "train_data = scaler.fit_transform(df.iloc[:train_size][features])\n",
    "val_data = scaler.transform(df.iloc[train_size:train_size+val_size][features])\n",
    "test_data = scaler.transform(df.iloc[train_size+val_size:][features])\n",
    "\n",
    "# Scale targets - fixed the target variable handling\n",
    "train_targets = target_scaler.fit_transform(df.iloc[:train_size][[target]])\n",
    "val_targets = target_scaler.transform(df.iloc[train_size:train_size+val_size][[target]])\n",
    "test_targets = target_scaler.transform(df.iloc[train_size+val_size:][[target]])\n",
    "\n",
    "# ================== 3. Temporal Convolutional Network ==================\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = nn.Sequential(\n",
    "            weight_norm(nn.Conv1d(input_size, num_channels, kernel_size, padding=(kernel_size-1)//2 + (kernel_size-1)%2)),  # Fixed padding\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            weight_norm(nn.Conv1d(num_channels, num_channels*2, kernel_size, padding=(kernel_size-1)//2 + (kernel_size-1)%2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            weight_norm(nn.Conv1d(num_channels*2, output_size, kernel_size, padding=(kernel_size-1)//2 + (kernel_size-1)%2))\n",
    "        )\n",
    "        self.init_weights()\n",
    "        \n",
    "        # Add a linear layer to ensure output size matches horizon\n",
    "        self.linear = nn.Linear(output_size, output_size)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch, sequence, features]\n",
    "        x = x.permute(0, 2, 1)  # [batch, features, sequence]\n",
    "        \n",
    "        # Apply TCN layers\n",
    "        y = self.tcn(x)\n",
    "        \n",
    "        # Ensure we get the right-most output of the correct length\n",
    "        y = y[:, :, -1]\n",
    "        \n",
    "        # Apply final linear layer\n",
    "        y = self.linear(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "# ================== 4. Hybrid Loss Function ==================\n",
    "class TemporalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.mae = nn.L1Loss()\n",
    "        \n",
    "    def forward(self, preds, targets):\n",
    "        mse_loss = self.mse(preds, targets)\n",
    "        \n",
    "        # Prevent issues with batches of size 1 or prediction horizons of 1\n",
    "        if preds.size(1) > 1:\n",
    "            temporal_loss = self.mae(preds[:, 1:] - preds[:, :-1], \n",
    "                                   targets[:, 1:] - targets[:, :-1])\n",
    "        else:\n",
    "            temporal_loss = torch.tensor(0.0, device=preds.device)\n",
    "            \n",
    "        return self.alpha * mse_loss + (1 - self.alpha) * temporal_loss\n",
    "\n",
    "# ================== 5. Training Protocol ==================\n",
    "window_size = 21\n",
    "horizon = 3  # Predict next 3 days\n",
    "\n",
    "# Create sequences with error handling\n",
    "try:\n",
    "    X_train, y_train = create_sequences(train_data, train_targets, window_size, horizon)\n",
    "    X_val, y_val = create_sequences(val_data, val_targets, window_size, horizon)\n",
    "    X_test, y_test = create_sequences(test_data, test_targets, window_size, horizon)\n",
    "    \n",
    "    # Safety check for sequence creation\n",
    "    if len(X_train) == 0 or len(X_val) == 0 or len(X_test) == 0:\n",
    "        raise ValueError(\"Failed to create sequences - insufficient data\")\n",
    "    \n",
    "    # Fix target shapes - ensure they are 2D (batch_size, horizon)\n",
    "    y_train = y_train.reshape(y_train.shape[0], y_train.shape[1])\n",
    "    y_val = y_val.reshape(y_val.shape[0], y_val.shape[1])\n",
    "    y_test = y_test.reshape(y_test.shape[0], y_test.shape[1])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error in sequence creation: {e}\")\n",
    "    raise\n",
    "\n",
    "# Initialize model with error handling\n",
    "try:\n",
    "    model = TCN(\n",
    "        input_size=len(features), \n",
    "        output_size=horizon, \n",
    "        num_channels=64, \n",
    "        kernel_size=5, \n",
    "        dropout=0.4\n",
    "    ).to(device)\n",
    "    \n",
    "    # Use a more robust optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "    loss_fn = TemporalLoss(alpha=0.6)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error initializing model: {e}\")\n",
    "    raise\n",
    "\n",
    "# ================== 6. Advanced Training Loop with Error Handling ==================\n",
    "try:\n",
    "    # Convert data to PyTorch tensors once to avoid repeated conversion\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Training parameters\n",
    "    batch_size = 32\n",
    "    epochs = 200\n",
    "    patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    # Training loop with early stopping\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        # Create random indices for shuffling\n",
    "        indices = torch.randperm(len(X_train_tensor))\n",
    "        \n",
    "        # Process in batches\n",
    "        for i in range(0, len(indices), batch_size):\n",
    "            # Get batch indices\n",
    "            batch_indices = indices[i:i+batch_size]\n",
    "            \n",
    "            # Get batch data\n",
    "            x_batch = X_train_tensor[batch_indices]\n",
    "            y_batch = y_train_tensor[batch_indices]\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            \n",
    "            # Ensure outputs and targets have same shape\n",
    "            if outputs.shape != y_batch.shape:\n",
    "                raise ValueError(f\"Shape mismatch: outputs {outputs.shape}, targets {y_batch.shape}\")\n",
    "                \n",
    "            # Calculate loss\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Record loss\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = loss_fn(val_outputs, y_val_tensor)\n",
    "            \n",
    "        # Update learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Train Loss {np.mean(train_losses):.4f}, Val Loss {val_loss.item():.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "    # Save checkpoint if possible\n",
    "    try:\n",
    "        torch.save(model.state_dict(), 'emergency_model.pth')\n",
    "        print(\"Saved emergency checkpoint\")\n",
    "    except:\n",
    "        print(\"Failed to save emergency checkpoint\")\n",
    "    raise\n",
    "\n",
    "# ================== 7. Final Ensemble Prediction with Uncertainty Quantification ==================\n",
    "try:\n",
    "    model.eval()\n",
    "    \n",
    "    # Create uncertainty-aware predictions using Monte Carlo Dropout\n",
    "    test_preds = []\n",
    "    model.train()  # Set to train mode to enable dropout for MC sampling\n",
    "    \n",
    "    n_samples = 10\n",
    "    for _ in range(n_samples):\n",
    "        with torch.no_grad():\n",
    "            pred = model(X_test_tensor).cpu().numpy()\n",
    "            test_preds.append(pred)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    final_preds = np.median(test_preds, axis=0)\n",
    "    pred_std = np.std(test_preds, axis=0)\n",
    "    \n",
    "    # Calculate confidence intervals (95%)\n",
    "    lower_bound = np.percentile(test_preds, 2.5, axis=0)\n",
    "    upper_bound = np.percentile(test_preds, 97.5, axis=0)\n",
    "    \n",
    "    # Inverse transform predictions back to original scale\n",
    "    final_preds_orig = target_scaler.inverse_transform(final_preds.reshape(-1, 1)).reshape(final_preds.shape)\n",
    "    lower_bound_orig = target_scaler.inverse_transform(lower_bound.reshape(-1, 1)).reshape(lower_bound.shape)\n",
    "    upper_bound_orig = target_scaler.inverse_transform(upper_bound.reshape(-1, 1)).reshape(upper_bound.shape)\n",
    "    y_test_orig = target_scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(y_test.shape)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n",
    "    raise\n",
    "\n",
    "# ================== 8. Kalman Filter Post-processing ==================\n",
    "try:\n",
    "    # Initialize Kalman Filter for smoothing predictions\n",
    "    kf = KalmanFilter(\n",
    "        initial_state_mean=final_preds_orig[0],\n",
    "        initial_state_covariance=np.eye(horizon) * 0.01,\n",
    "        transition_matrices=np.eye(horizon),\n",
    "        observation_matrices=np.eye(horizon),\n",
    "        observation_covariance=0.1 * np.eye(horizon),\n",
    "        transition_covariance=0.01 * np.eye(horizon)\n",
    "    )\n",
    "    \n",
    "    # Apply Kalman Filter smoothing\n",
    "    smoothed_state_means, _ = kf.smooth(final_preds_orig)\n",
    "    \n",
    "    # Final predictions after filtering\n",
    "    final_filtered_preds = smoothed_state_means\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during Kalman filtering, using unfiltered predictions: {e}\")\n",
    "    final_filtered_preds = final_preds_orig\n",
    "\n",
    "# ================== 9. Visualization and Evaluation ==================\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(actual, predicted):\n",
    "    mse = np.mean((actual - predicted) ** 2)\n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "    mape = np.mean(np.abs((actual - predicted) / np.maximum(0.0001, np.abs(actual)))) * 100\n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'RMSE': np.sqrt(mse),\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# Calculate metrics for each day in horizon\n",
    "metrics_by_day = []\n",
    "overall_metrics = {}\n",
    "for i in range(horizon):\n",
    "    day_metrics = calculate_metrics(\n",
    "        y_test_orig[:, i].flatten(), \n",
    "        final_filtered_preds[:, i].flatten()\n",
    "    )\n",
    "    metrics_by_day.append(day_metrics)\n",
    "    print(f\"Day {i+1} Metrics: {day_metrics}\")\n",
    "    \n",
    "    # Store Day 1 metrics for main visualization\n",
    "    if i == 0:\n",
    "        overall_metrics = day_metrics\n",
    "\n",
    "test_rmse = overall_metrics['RMSE']\n",
    "test_mape = overall_metrics['MAPE']\n",
    "\n",
    "# Create visualization directory if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('visualizations'):\n",
    "    os.makedirs('visualizations')\n",
    "\n",
    "# ===== VISUALIZATION 1: SIMPLE COMPARISON PLOT =====\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_orig[:, 0], label='Actual Prices', linewidth=2)\n",
    "plt.plot(final_filtered_preds[:, 0], label=f'Predicted Prices (RMSE: {test_rmse:.2f})', alpha=0.7, linewidth=2)\n",
    "plt.title('AAPL Stock Price Prediction Performance', fontsize=16)\n",
    "plt.xlabel('Test Sample Index', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('visualizations/simple_prediction_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# ===== VISUALIZATION 2: MULTI-DAY FORECAST =====\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(horizon):\n",
    "    day_rmse = metrics_by_day[i]['RMSE']\n",
    "    plt.plot(y_test_orig[:, i], '-', label=f'Actual (Day {i+1})', linewidth=2)\n",
    "    plt.plot(final_filtered_preds[:, i], '--', label=f'Predicted (Day {i+1}, RMSE: {day_rmse:.2f})', linewidth=2)\n",
    "\n",
    "plt.title('Multi-Day Stock Price Forecast', fontsize=16)\n",
    "plt.xlabel('Test Sample Index', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('visualizations/multi_day_forecast.png')\n",
    "plt.close()\n",
    "\n",
    "# ===== VISUALIZATION 3: PREDICTION WITH CONFIDENCE INTERVALS =====\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(y_test_orig[:, 0], 'k-', label='Actual Prices', linewidth=2)\n",
    "plt.plot(final_filtered_preds[:, 0], 'b-', label=f'Predicted Prices (RMSE: {test_rmse:.2f})', linewidth=2)\n",
    "plt.fill_between(\n",
    "    range(len(y_test_orig)),\n",
    "    lower_bound_orig[:, 0],\n",
    "    upper_bound_orig[:, 0],\n",
    "    color='blue',\n",
    "    alpha=0.2,\n",
    "    label='95% Confidence Interval'\n",
    ")\n",
    "plt.title('Stock Price Prediction with Uncertainty Bounds', fontsize=16)\n",
    "plt.xlabel('Test Sample Index', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('visualizations/prediction_with_confidence.png')\n",
    "plt.close()\n",
    "\n",
    "# ===== VISUALIZATION 4: ZOOM IN ON SPECIFIC SECTION =====\n",
    "# Focus on last 30 days or fewer if not enough data\n",
    "zoom_range = min(30, len(y_test_orig))\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(y_test_orig[-zoom_range:, 0], 'r-', label='Actual Prices', linewidth=2.5)\n",
    "plt.plot(final_filtered_preds[-zoom_range:, 0], 'g-', label=f'Predicted Prices', linewidth=2.5)\n",
    "plt.fill_between(\n",
    "    range(zoom_range),\n",
    "    lower_bound_orig[-zoom_range:, 0],\n",
    "    upper_bound_orig[-zoom_range:, 0],\n",
    "    color='green',\n",
    "    alpha=0.2,\n",
    "    label='95% Confidence Interval'\n",
    ")\n",
    "\n",
    "# Add error metrics to plot\n",
    "plt.text(\n",
    "    0.02, 0.95, \n",
    "    f'RMSE: {test_rmse:.2f}\\nMAPE: {test_mape:.2f}%', \n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=12,\n",
    "    bbox=dict(facecolor='white', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.title('Recent Stock Price Predictions (Last 30 Days)', fontsize=16)\n",
    "plt.xlabel('Days', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('visualizations/recent_predictions.png')\n",
    "plt.close()\n",
    "\n",
    "# ===== VISUALIZATION 5: ERROR ANALYSIS =====\n",
    "errors = y_test_orig[:, 0] - final_filtered_preds[:, 0]\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Error distribution\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(errors, bins=30, alpha=0.7, color='b')\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.title('Prediction Error Distribution', fontsize=16)\n",
    "plt.xlabel('Error Value', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Error over time\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(errors, 'b-', label='Prediction Error', linewidth=2)\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.title('Prediction Error Over Time', fontsize=16)\n",
    "plt.xlabel('Test Sample Index', fontsize=12)\n",
    "plt.ylabel('Error Value', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/error_analysis.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Visualizations saved to 'visualizations' directory.\")\n",
    "\n",
    "# Plot results - as requested in the exact format\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_orig[:, 0], label='Actual Prices', linewidth=2)\n",
    "plt.plot(final_filtered_preds[:, 0], label=f'Predicted Prices (RMSE: {test_rmse:.2f})', alpha=0.7, linewidth=2)\n",
    "plt.title(f'AAPL Price Prediction (Test RMSE: {test_rmse:.2f})', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('visualizations/requested_visualization.png')\n",
    "plt.show()  # This will display the plot if running in an interactive environment\n",
    "\n",
    "\n",
    "print(\"Analysis complete. Results saved.\")\n",
    "\n",
    "# ================== 10. Enhanced Investment Returns Analysis with Risk Management ==================\n",
    "# Replace the original calculate_investment_returns function with this enhanced version\n",
    "def calculate_investment_returns(actual_prices, predicted_prices, prediction_std=None, initial_investment=100.0, trading_fee_percent=0.1):\n",
    "    \"\"\"\n",
    "    Calculate investment returns using a strategy with multiple risk management techniques:\n",
    "    - Position sizing based on prediction confidence\n",
    "    - Stop-loss implementation\n",
    "    - Volatility-based adjustment\n",
    "    - Trend following filter\n",
    "    - Lower exposure during uncertain markets\n",
    "    \"\"\"\n",
    "    # Initialize variables\n",
    "    cash = initial_investment\n",
    "    shares = 0\n",
    "    portfolio_values = [initial_investment]  # Starting portfolio value\n",
    "    actions = []  # Track buy/sell/hold actions\n",
    "    \n",
    "    # Use actual close prices for valuation\n",
    "    actual_close_prices = actual_prices[:, 0]\n",
    "    day1_predictions = predicted_prices[:, 0]\n",
    "    try:\n",
    "        # Convert list of predictions to 3D numpy array\n",
    "        # Shape: (num_ensemble_runs, num_samples, prediction_horizon)\n",
    "        test_preds_array = np.array(test_preds)\n",
    "        \n",
    "        # Verify we have a 3D array\n",
    "        if test_preds_array.ndim != 3:\n",
    "            raise ValueError(\"Predictions should be 3D array: (runs, samples, horizon)\")\n",
    "        \n",
    "        # Calculate std for first prediction step across all runs\n",
    "        prediction_std = np.std(test_preds_array[:, :, 0], axis=0)  # Shape: (num_samples,)\n",
    "        print(f\"Using prediction std with shape: {prediction_std.shape}\")\n",
    "    finally:    \n",
    "        # If no prediction standard deviation is provided, create a default one\n",
    "        if prediction_std is None:\n",
    "            prediction_std = np.ones_like(day1_predictions) * 0.01\n",
    "       \n",
    "    # Add validation checks at the start of the function\n",
    "    \n",
    "    if prediction_std is not None:\n",
    "        assert len(prediction_std) == len(actual_prices), \\\n",
    "            \"prediction_std must match actual_prices length\"\n",
    "        assert prediction_std.ndim == 1, \\\n",
    "            \"prediction_std must be 1D array\"\n",
    "        \n",
    "    # Track entries for stop loss calculation\n",
    "    entry_prices = []\n",
    "    max_drawdown = 0\n",
    "    peak_value = initial_investment\n",
    "    \n",
    "    # Risk management parameters\n",
    "    max_position_pct = 0.6  # Maximum position size as percentage of portfolio\n",
    "    stop_loss_pct = 0.05  # 5% stop loss\n",
    "    trailing_stop_pct = 0.07  # 7% trailing stop loss\n",
    "    profit_take_pct = 0.1  # 10% profit taking\n",
    "    confidence_threshold = 0.01  # Minimum predicted change to trigger a trade\n",
    "    \n",
    "    # For market regime detection\n",
    "    window_size = min(20, len(actual_close_prices) - 1)  # Use smaller window if not enough data\n",
    "    \n",
    "    for i in range(len(actual_close_prices) - 1):\n",
    "        current_price = actual_close_prices[i]\n",
    "        \n",
    "        # Calculate current portfolio value\n",
    "        current_portfolio_value = cash + shares * current_price\n",
    "        \n",
    "        # Update maximum drawdown\n",
    "        if current_portfolio_value > peak_value:\n",
    "            peak_value = current_portfolio_value\n",
    "        current_drawdown = (peak_value - current_portfolio_value) / peak_value * 100\n",
    "        max_drawdown = max(max_drawdown, current_drawdown)\n",
    "        \n",
    "        # Skip first day (we need previous data)\n",
    "        if i <= 0:\n",
    "            actions.append(\"Day 0: Initial position\")\n",
    "            portfolio_values.append(current_portfolio_value)\n",
    "            continue\n",
    "        \n",
    "        # ===== RISK MANAGEMENT TECHNIQUE 1: Market Regime Detection =====\n",
    "        # Simple moving average crossover for trend detection\n",
    "        if i >= window_size:\n",
    "            short_ma = np.mean(actual_close_prices[i-window_size//2:i])\n",
    "            long_ma = np.mean(actual_close_prices[i-window_size:i])\n",
    "            market_trend = \"UPTREND\" if short_ma > long_ma else \"DOWNTREND\"\n",
    "        else:\n",
    "            # Not enough data, assume neutral\n",
    "            market_trend = \"NEUTRAL\" \n",
    "        \n",
    "        # ===== RISK MANAGEMENT TECHNIQUE 2: Volatility Assessment =====\n",
    "        # Calculate recent volatility\n",
    "        if i >= window_size:\n",
    "            recent_returns = np.diff(actual_close_prices[i-window_size:i]) / actual_close_prices[i-window_size:i-1]\n",
    "            current_volatility = np.std(recent_returns)\n",
    "            avg_volatility = 0.015  # Typical stock daily volatility\n",
    "            volatility_ratio = current_volatility / avg_volatility\n",
    "        else:\n",
    "            volatility_ratio = 1.0  # Default to normal\n",
    "        \n",
    "        # ===== RISK MANAGEMENT TECHNIQUE 3: Confidence-Based Trading =====\n",
    "        # What our model predicted for tomorrow\n",
    "        predicted_next_price = day1_predictions[i]\n",
    "        predicted_change_percent = (predicted_next_price - current_price) / current_price\n",
    "        \n",
    "        # Modify confidence calculation to prevent division by zero\n",
    "        prediction_confidence = 1.0 / (1.0 + prediction_std[i] + 1e-8)  # Add epsilon        \n",
    "        \n",
    "        # Only trade if the predicted change exceeds our threshold and aligns with market trend\n",
    "        valid_signal = abs(predicted_change_percent) > confidence_threshold\n",
    "        \n",
    "        # ===== RISK MANAGEMENT TECHNIQUE 4: Stop Loss Check =====\n",
    "        # Check if we need to exit due to stop loss\n",
    "        stop_loss_triggered = False\n",
    "        if shares > 0 and len(entry_prices) > 0:\n",
    "            # Calculate average entry price\n",
    "            avg_entry_price = sum(entry_prices) / len(entry_prices)\n",
    "            \n",
    "            # Fixed stop loss\n",
    "            if current_price < avg_entry_price * (1 - stop_loss_pct):\n",
    "                stop_loss_triggered = True\n",
    "                actions.append(f\"Day {i}: STOP LOSS TRIGGERED at ${current_price:.2f} (Entry: ${avg_entry_price:.2f})\")\n",
    "            \n",
    "            # Trailing stop loss\n",
    "            elif shares > 0:\n",
    "                # Calculate highest price since entry\n",
    "                highest_since_entry = max(actual_close_prices[i-len(entry_prices):i+1])\n",
    "                if current_price < highest_since_entry * (1 - trailing_stop_pct):\n",
    "                    stop_loss_triggered = True\n",
    "                    actions.append(f\"Day {i}: TRAILING STOP TRIGGERED at ${current_price:.2f} (High: ${highest_since_entry:.2f})\")\n",
    "            \n",
    "            # Take profit\n",
    "            elif current_price > avg_entry_price * (1 + profit_take_pct):\n",
    "                actions.append(f\"Day {i}: PROFIT TARGET REACHED at ${current_price:.2f}\")\n",
    "                stop_loss_triggered = True  # Use same mechanism to exit\n",
    "        \n",
    "        # Execute stop loss if triggered\n",
    "        if stop_loss_triggered and shares > 0:\n",
    "            # Sell all shares\n",
    "            trade_value = shares * current_price\n",
    "            fee = trade_value * (trading_fee_percent/100)\n",
    "            \n",
    "            # Update portfolio\n",
    "            cash += (trade_value - fee)\n",
    "            shares = 0\n",
    "            entry_prices = []  # Reset entry prices\n",
    "        \n",
    "        # Regular trading logic with risk management\n",
    "        elif valid_signal:\n",
    "            # FIX: Ensure predicted_trend is a scalar boolean, not an array\n",
    "            predicted_trend = float(predicted_next_price) > current_price\n",
    "            \n",
    "            # ===== RISK MANAGEMENT TECHNIQUE 5: Position Sizing =====\n",
    "            # Adjust position size based on:\n",
    "            # 1. Prediction confidence\n",
    "            # 2. Market volatility\n",
    "            # 3. Market trend\n",
    "            \n",
    "            # Base position size as percentage of portfolio\n",
    "            base_position_pct = max_position_pct * prediction_confidence\n",
    "            \n",
    "            # Reduce position in high volatility\n",
    "            if volatility_ratio > 1.5:\n",
    "                position_pct = base_position_pct * 0.5\n",
    "            elif volatility_ratio > 1.2:\n",
    "                position_pct = base_position_pct * 0.75\n",
    "            else:\n",
    "                position_pct = base_position_pct\n",
    "            \n",
    "            # Consider market trend - reduce position if trading against trend\n",
    "            if (predicted_trend and market_trend == \"DOWNTREND\") or \\\n",
    "               (not predicted_trend and market_trend == \"UPTREND\"):\n",
    "                position_pct *= 0.5  # Reduce position when trading against trend\n",
    "            \n",
    "            # Execute trade with adjusted position size\n",
    "            if predicted_trend and cash > 0:  # Model predicts price will go up, buy\n",
    "                # Calculate position size\n",
    "                # Modify the cash_to_use calculation in the trading loop\n",
    "                cash_to_use = float(current_portfolio_value * position_pct)\n",
    "                cash_to_use = min(cash_to_use, cash)  # Now comparing two scalars\n",
    "                if cash_to_use > 0:\n",
    "                    # Calculate shares to buy with adjusted cash amount\n",
    "                    shares_to_buy = cash_to_use / (current_price * (1 + trading_fee_percent/100))\n",
    "                    \n",
    "                    trade_cost = shares_to_buy * current_price\n",
    "                    fee = trade_cost * (trading_fee_percent/100)\n",
    "                    \n",
    "                    # Update portfolio\n",
    "                    shares += shares_to_buy\n",
    "                    cash -= (trade_cost + fee)\n",
    "                    actions.append(f\"Day {i}: BUY {shares_to_buy:.4f} shares at ${current_price:.2f} (Confidence: {prediction_confidence:.2f}, Volatility: {volatility_ratio:.1f}X)\")\n",
    "                    \n",
    "                    # Record entry for stop loss\n",
    "                    entry_prices.append(current_price)\n",
    "                else:\n",
    "                    actions.append(f\"Day {i}: HOLD - Signal too weak to trade\")\n",
    "                    \n",
    "            elif not predicted_trend and shares > 0:  # Model predicts price will go down, sell\n",
    "                # Calculate position size to sell (partial position)\n",
    "                shares_to_sell = shares * position_pct\n",
    "                \n",
    "                if shares_to_sell > 0:\n",
    "                    trade_value = shares_to_sell * current_price\n",
    "                    fee = trade_value * (trading_fee_percent/100)\n",
    "                    \n",
    "                    # Update portfolio\n",
    "                    cash += (trade_value - fee)\n",
    "                    shares -= shares_to_sell\n",
    "                    actions.append(f\"Day {i}: SELL {shares_to_sell:.4f} shares at ${current_price:.2f} (Confidence: {prediction_confidence:.2f})\")\n",
    "                    \n",
    "                    # Update entry prices if partial sale\n",
    "                    if shares > 0 and len(entry_prices) > 0:\n",
    "                        # Remove corresponding proportion of entry prices\n",
    "                        num_entries_to_remove = int(len(entry_prices) * (shares_to_sell / (shares + shares_to_sell)))\n",
    "                        entry_prices = entry_prices[num_entries_to_remove:]\n",
    "                else:\n",
    "                    actions.append(f\"Day {i}: HOLD - Signal too weak to trade\")\n",
    "                    \n",
    "            else:\n",
    "                actions.append(f\"Day {i}: HOLD (Cash: ${cash:.2f}, Shares: {shares:.4f})\")\n",
    "        else:\n",
    "            actions.append(f\"Day {i}: HOLD - No clear signal\")\n",
    "            \n",
    "        # Record portfolio value for this day\n",
    "        portfolio_values.append(cash + shares * current_price)\n",
    "    \n",
    "    # Calculate final portfolio value and return metrics\n",
    "    initial_value = portfolio_values[0]\n",
    "    final_value = portfolio_values[-1]\n",
    "    total_return = ((final_value / initial_value) - 1) * 100\n",
    "    \n",
    "    # Calculate annualized return (assuming 252 trading days per year)\n",
    "    days = len(portfolio_values) - 1\n",
    "    annualized_return = (((final_value / initial_value) ** (252 / days)) - 1) * 100\n",
    "    \n",
    "    return {\n",
    "        'initial_investment': initial_investment,\n",
    "        'final_value': final_value,\n",
    "        'total_return_percent': total_return,\n",
    "        'annualized_return_percent': annualized_return,\n",
    "        'max_drawdown_percent': max_drawdown,\n",
    "        'portfolio_values': portfolio_values,\n",
    "        'actions': actions\n",
    "    }\n",
    "\n",
    "# ===== Code to replace the existing investment analysis section =====\n",
    "# Calculate investment returns with the new risk management strategy\n",
    "print(\"\\n=== Running Enhanced Risk-Managed Investment Analysis ===\")\n",
    "\n",
    "# We'll use the prediction standard deviation for confidence-based position sizing\n",
    "# Extract standard deviation from the ensemble predictions if available\n",
    "try:\n",
    "    prediction_std = np.std(test_preds, axis=0)\n",
    "    print(f\"Using prediction standard deviation for confidence-based sizing\")\n",
    "except:\n",
    "    prediction_std = None\n",
    "    print(f\"No prediction standard deviation available, using default confidence\")\n",
    "\n",
    "# First, calculate the original investment results (assuming this is already done previously)\n",
    "# If not, uncomment the following:\n",
    "investment_results = calculate_original_investment_returns(y_test_orig, final_filtered_preds, initial_investment=100.0)\n",
    "\n",
    "# ===== Safe Prediction Standard Deviation Calculation =====\n",
    "try:\n",
    "    # Ensure we have numpy arrays\n",
    "    if isinstance(test_preds, list):\n",
    "        test_preds_array = np.stack(test_preds)  # Convert list of arrays to 3D array\n",
    "    else:\n",
    "        test_preds_array = test_preds.copy()\n",
    "    \n",
    "    # Verify array dimensions\n",
    "    if test_preds_array.ndim == 2:\n",
    "        # Handle single-run predictions (add ensemble dimension)\n",
    "        test_preds_array = test_preds_array[np.newaxis, ...]\n",
    "    \n",
    "    # Calculate standard deviation for first prediction step\n",
    "    prediction_std = np.std(test_preds_array[:, :, 0], axis=0)\n",
    "    print(f\"Successfully calculated prediction std (shape: {prediction_std.shape})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Prediction std calculation failed: {e}\")\n",
    "    prediction_std = np.ones(len(y_test_orig)) * 0.05  # Default 5% uncertainty\n",
    "    print(\"Using default prediction standard deviation\")\n",
    "\n",
    "# Now use in your investment calculation\n",
    "risk_managed_results = calculate_investment_returns(\n",
    "    y_test_orig, \n",
    "    final_filtered_preds,\n",
    "    prediction_std=prediction_std,\n",
    "    initial_investment=100.0,\n",
    "    trading_fee_percent=0.1\n",
    ")\n",
    "# Print investment metrics\n",
    "print(\"\\n=== Risk-Managed Investment Performance (Starting with $100) ===\")\n",
    "print(f\"Final Portfolio Value: ${risk_managed_results['final_value']:.2f}\")\n",
    "print(f\"Total Return: {risk_managed_results['total_return_percent']:.2f}%\")\n",
    "print(f\"Annualized Return: {risk_managed_results['annualized_return_percent']:.2f}%\")\n",
    "print(f\"Maximum Drawdown: {risk_managed_results['max_drawdown_percent']:.2f}%\")\n",
    "print(f\"Drawdown Reduction: {investment_results['max_drawdown_percent'] - risk_managed_results['max_drawdown_percent']:.2f}%\")\n",
    "\n",
    "# Compare with original strategy\n",
    "performance_ratio = risk_managed_results['total_return_percent'] / max(1.0, investment_results['total_return_percent'])\n",
    "print(f\"Performance ratio vs original: {performance_ratio:.2f}x\")\n",
    "\n",
    "# ===== Additional Visualization for Risk-Managed Strategy =====\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot portfolio values for both strategies\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(investment_results['portfolio_values'], 'r-', label='Original Strategy', linewidth=2)\n",
    "plt.plot(risk_managed_results['portfolio_values'], 'g-', label='Risk-Managed Strategy', linewidth=2)\n",
    "plt.title('Portfolio Value Comparison', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=12)\n",
    "plt.ylabel('Portfolio Value ($)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot drawdowns for both strategies\n",
    "plt.subplot(2, 1, 2)\n",
    "original_drawdowns = []\n",
    "managed_drawdowns = []\n",
    "\n",
    "# Calculate drawdown series for original strategy\n",
    "peak = investment_results['portfolio_values'][0]\n",
    "for value in investment_results['portfolio_values']:\n",
    "    if value > peak:\n",
    "        peak = value\n",
    "    drawdown = (peak - value) / peak * 100\n",
    "    original_drawdowns.append(drawdown)\n",
    "\n",
    "# Calculate drawdown series for risk-managed strategy\n",
    "peak = risk_managed_results['portfolio_values'][0]\n",
    "for value in risk_managed_results['portfolio_values']:\n",
    "    if value > peak:\n",
    "        peak = value\n",
    "    drawdown = (peak - value) / peak * 100\n",
    "    managed_drawdowns.append(drawdown)\n",
    "\n",
    "plt.plot(original_drawdowns, 'r-', label=f'Original Drawdown (Max: {investment_results[\"max_drawdown_percent\"]:.2f}%)', linewidth=2)\n",
    "plt.plot(managed_drawdowns, 'g-', label=f'Managed Drawdown (Max: {risk_managed_results[\"max_drawdown_percent\"]:.2f}%)', linewidth=2)\n",
    "plt.title('Drawdown Comparison', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=12)\n",
    "plt.ylabel('Drawdown (%)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gca().invert_yaxis()  # Invert Y axis to show drawdowns as negative values\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/risk_management_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Create a summary plot for presentation\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(risk_managed_results['portfolio_values'], 'g-', linewidth=2.5)\n",
    "plt.title(f'Risk-Managed Portfolio Growth (Starting with $100)', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=12)\n",
    "plt.ylabel('Portfolio Value ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add key metrics as text\n",
    "plt.text(\n",
    "    0.02, 0.85, \n",
    "    f'Final Value: ${risk_managed_results[\"final_value\"]:.2f}\\n'\n",
    "    f'Total Return: {risk_managed_results[\"total_return_percent\"]:.2f}%\\n'\n",
    "    f'Annualized: {risk_managed_results[\"annualized_return_percent\"]:.2f}%\\n'\n",
    "    f'Max Drawdown: {risk_managed_results[\"max_drawdown_percent\"]:.2f}%\\n'\n",
    "    f'Original Drawdown: {investment_results[\"max_drawdown_percent\"]:.2f}%', \n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=12,\n",
    "    bbox=dict(facecolor='white', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/risk_managed_portfolio.png')\n",
    "plt.show()  # This will display the plot if running in an interactive environment\n",
    "\n",
    "# Save detailed trading log with risk-managed approach\n",
    "with open('visualizations/risk_managed_trading_log.txt', 'w') as f:\n",
    "    f.write(\"=== Risk-Managed Investment Trading Log ===\\n\")\n",
    "    f.write(f\"Initial Investment: ${risk_managed_results['initial_investment']:.2f}\\n\")\n",
    "    f.write(f\"Final Portfolio Value: ${risk_managed_results['final_value']:.2f}\\n\")\n",
    "    f.write(f\"Total Return: {risk_managed_results['total_return_percent']:.2f}%\\n\")\n",
    "    f.write(f\"Annualized Return: {risk_managed_results['annualized_return_percent']:.2f}%\\n\")\n",
    "    f.write(f\"Maximum Drawdown: {risk_managed_results['max_drawdown_percent']:.2f}%\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== Risk Management Improvements ===\\n\")\n",
    "    f.write(f\"Original Max Drawdown: {investment_results['max_drawdown_percent']:.2f}%\\n\")\n",
    "    f.write(f\"Drawdown Reduction: {investment_results['max_drawdown_percent'] - risk_managed_results['max_drawdown_percent']:.2f}%\\n\")\n",
    "    f.write(f\"Performance Ratio: {performance_ratio:.2f}x\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== Risk Management Techniques Applied ===\\n\")\n",
    "    f.write(\"1. Position Sizing: Adjusted position sizes based on prediction confidence\\n\")\n",
    "    f.write(\"2. Stop-Loss Protection: Implemented 5% fixed and 7% trailing stop losses\\n\")\n",
    "    f.write(\"3. Volatility Adjustment: Reduced exposure during high volatility periods\\n\")\n",
    "    f.write(\"4. Trend Following: Aligned positions with overall market trend\\n\")\n",
    "    f.write(\"5. Profit Taking: Implemented 10% profit-taking threshold\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== Detailed Trading Actions ===\\n\")\n",
    "    for action in risk_managed_results['actions']:\n",
    "        f.write(f\"{action}\\n\")\n",
    "\n",
    "print(\"\\n=== Risk Management Analysis Complete ===\")\n",
    "print(\"Enhanced trading strategy results and comparisons saved to visualizations directory\")\n",
    "print(f\"Drawdown reduced from {investment_results['max_drawdown_percent']:.2f}% to {risk_managed_results['max_drawdown_percent']:.2f}%\")\n",
    "\n",
    "# ===== VISUALIZATION 6: INVESTMENT RETURNS =====\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot portfolio value over time\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(investment_results['portfolio_values'], 'g-', linewidth=2)\n",
    "plt.title('Portfolio Value Over Time (Starting with $100)', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=12)\n",
    "plt.ylabel('Portfolio Value ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add buy/sell markers\n",
    "buy_days = []\n",
    "buy_values = []\n",
    "sell_days = []\n",
    "sell_values = []\n",
    "\n",
    "for i, action in enumerate(investment_results['actions']):\n",
    "    if 'BUY' in action:\n",
    "        buy_days.append(i)\n",
    "        buy_values.append(investment_results['portfolio_values'][i])\n",
    "    elif 'SELL' in action:\n",
    "        sell_days.append(i)\n",
    "        sell_values.append(investment_results['portfolio_values'][i])\n",
    "\n",
    "plt.scatter(buy_days, buy_values, color='blue', marker='^', s=100, label='Buy')\n",
    "plt.scatter(sell_days, sell_values, color='red', marker='v', s=100, label='Sell')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Plot price and predictions with buy/sell signals\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(y_test_orig[:, 0], 'k-', label='Actual Price', linewidth=2)\n",
    "plt.plot(final_filtered_preds[:, 0], 'b--', label='Predicted Price', linewidth=2, alpha=0.7)\n",
    "\n",
    "# Add buy/sell markers\n",
    "plt.scatter(buy_days, [y_test_orig[day, 0] for day in buy_days], color='blue', marker='^', s=100, label='Buy Signal')\n",
    "plt.scatter(sell_days, [y_test_orig[day, 0] for day in sell_days], color='red', marker='v', s=100, label='Sell Signal')\n",
    "\n",
    "plt.title('Stock Price with Trading Signals', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/investment_returns.png')\n",
    "plt.close()\n",
    "\n",
    "# Save detailed trading log\n",
    "with open('visualizations/trading_log.txt', 'w') as f:\n",
    "    f.write(\"=== Investment Trading Log ===\\n\")\n",
    "    f.write(f\"Initial Investment: ${investment_results['initial_investment']:.2f}\\n\")\n",
    "    f.write(f\"Final Portfolio Value: ${investment_results['final_value']:.2f}\\n\")\n",
    "    f.write(f\"Total Return: {investment_results['total_return_percent']:.2f}%\\n\")\n",
    "    f.write(f\"Annualized Return: {investment_results['annualized_return_percent']:.2f}%\\n\")\n",
    "    f.write(f\"Maximum Drawdown: {investment_results['max_drawdown_percent']:.2f}%\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== Detailed Trading Actions ===\\n\")\n",
    "    for action in investment_results['actions']:\n",
    "        f.write(f\"{action}\\n\")\n",
    "\n",
    "# ================== 11. Advanced Model Comparison ==================\n",
    "# Here we implement a baseline model to compare against our advanced model\n",
    "# This helps validate that our sophisticated approach is actually better\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare data for baseline models (using the same window size)\n",
    "X_train_2d = X_train.reshape(X_train.shape[0], -1)  # Flatten the window dimensions\n",
    "X_test_2d = X_test.reshape(X_test.shape[0], -1)  # Flatten the window dimensions\n",
    "\n",
    "# Train a linear regression baseline\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_2d, y_train[:, 0])  # Predict first day only for simplicity\n",
    "lr_preds = lr_model.predict(X_test_2d)\n",
    "\n",
    "# Train a random forest baseline\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_2d, y_train[:, 0])  # Predict first day only for simplicity\n",
    "rf_preds = rf_model.predict(X_test_2d)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "lr_preds_orig = target_scaler.inverse_transform(lr_preds.reshape(-1, 1)).flatten()\n",
    "rf_preds_orig = target_scaler.inverse_transform(rf_preds.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate metrics for baselines\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test_orig[:, 0], lr_preds_orig))\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test_orig[:, 0], rf_preds_orig))\n",
    "deep_model_rmse = metrics_by_day[0]['RMSE']\n",
    "\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"Deep TCN Model RMSE: {deep_model_rmse:.2f}\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"Linear Regression RMSE: {lr_rmse:.2f}\")\n",
    "print(f\"Improvement over Linear Regression: {(1 - deep_model_rmse/lr_rmse) * 100:.2f}%\")\n",
    "print(f\"Improvement over Random Forest: {(1 - deep_model_rmse/rf_rmse) * 100:.2f}%\")\n",
    "\n",
    "# ===== VISUALIZATION 7: MODEL COMPARISON =====\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot predictions from all models\n",
    "plt.plot(y_test_orig[:, 0], 'k-', label='Actual Price', linewidth=2.5)\n",
    "plt.plot(final_filtered_preds[:, 0], 'b-', label=f'Deep TCN (RMSE: {deep_model_rmse:.2f})', linewidth=2)\n",
    "plt.plot(rf_preds_orig, 'g--', label=f'Random Forest (RMSE: {rf_rmse:.2f})', linewidth=1.5, alpha=0.7)\n",
    "plt.plot(lr_preds_orig, 'r:', label=f'Linear Regression (RMSE: {lr_rmse:.2f})', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "plt.title('Model Comparison', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=12)\n",
    "plt.ylabel('Stock Price ($)', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig('visualizations/model_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Display summary report\n",
    "print(\"\\n=== SUMMARY REPORT ===\")\n",
    "print(f\"Our model predicts that starting with $100 would result in ${investment_results['final_value']:.2f}\")\n",
    "print(f\"This represents a {investment_results['total_return_percent']:.2f}% return over the test period\")\n",
    "print(f\"The model outperformed simple baselines by up to {max((1 - deep_model_rmse/lr_rmse) * 100, (1 - deep_model_rmse/rf_rmse) * 100):.2f}%\")\n",
    "print(f\"Maximum drawdown during trading: {investment_results['max_drawdown_percent']:.2f}%\")\n",
    "print(f\"Trading summary: {len(buy_days)} buys, {len(sell_days)} sells\")\n",
    "print(\"\\nVisualization and detailed logs saved to the 'visualizations' directory\")\n",
    "\n",
    "# Create final portfolio value plot for immediate display\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(investment_results['portfolio_values'], 'g-', linewidth=2.5)\n",
    "plt.title(f'Portfolio Value Over Time (Starting with $100)', fontsize=16)\n",
    "plt.xlabel('Trading Days', fontsize=12)\n",
    "plt.ylabel('Portfolio Value ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add key metrics as text\n",
    "plt.text(\n",
    "    0.02, 0.85, \n",
    "    f'Final Value: ${investment_results[\"final_value\"]:.2f}\\n'\n",
    "    f'Total Return: {investment_results[\"total_return_percent\"]:.2f}%\\n'\n",
    "    f'Annualized Return: {investment_results[\"annualized_return_percent\"]:.2f}%\\n'\n",
    "    f'Max Drawdown: {investment_results[\"max_drawdown_percent\"]:.2f}%', \n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=12,\n",
    "    bbox=dict(facecolor='white', alpha=0.8)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/final_portfolio_value.png')\n",
    "plt.show()  # This will display the plot if running in an interactive environmentment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
